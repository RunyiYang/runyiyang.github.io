<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="SUNDAE: Spectrally Pruned Gaussian Fields with Neural Compensation">
  <meta name="keywords" content="SUNDAE: Spectrally Pruned Gaussian Fields with Neural Compensation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SUNDAE</title>

  <!-- Bootstrap -->
  <link rel="stylesheet" href="../../static/css/bootstrap-4.4.1.css">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  
  
  
  
  <link rel="stylesheet" href="../../static/css/bulma.min.css">
  <link rel="stylesheet" href="../../static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="../../static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="../../static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="../../static/css/index.css">
  <link rel="icon" href="../../static/images/icon.png">

  

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="../../static/js/fontawesome.all.min.js"></script>
  <script src="../../static/js/bulma-carousel.min.js"></script>
  <script src="../../static/js/bulma-slider.min.js"></script>
  <script src="../../static/js/index.js"></script>
  <script src="../../static/js/app.js"></script>
  <script src="../../static/js/video_comparison.js"></script>
  <script src="../../static/js/video_comparison_3.js"></script>

  <link rel="stylesheet" href="../../static/css/dics.original.css">
  <link rel="stylesheet" href="../../static/css/dics2.original.css">
  <script src="../../static/js/event_handler.js"></script>
  <script src="../../static/js/dics.original.js"></script>
  <script src="../../static/js/dics2.original.js"></script>
  <script>
    function openDemo(demoName) {
      window.location = 'https://KevinSONG729.github.io/project-pages/SA-GS/demo/' + demoName + '.html';
    }
  </script>

</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title" style="margin-bottom: 0"><strong>SUNDAE: Spectrally Pruned Gaussian Fields with Neural Compensation</strong></h1>
          <!-- <h2 class="title is-2 publication-title" style="margin-top: 0; margin-bottom: 0"></h2> -->
          
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://runyiyang.github.io/">Runyi Yang</a><sup>1,2</sup></span>, 
            <span class="author-block">
              <a href="https://github.com/jike5">Zhenxin Zhu</a><sup>1,3</sup></span>, 
            <span class="author-block">
              <a href="https://github.com/Jzian">Zhou Jiang</a><sup>1,4</sup>, 
            </span>
            <span class="author-block">
              Baijun Ye<sup>1, 4</sup>, 
            </span>
            <br>
            <span class="author-block">
              Xiaoxue Chen<sup>1</sup>, 
            </span>
            <span class="author-block">
              Yifei Zhang<sup>1,5</sup>, 
            </span>
            <span class="author-block">
              <a href="https://tao-11-chen.github.io/">Yuantao Chen</a><sup>1,6</sup>, 
            </span>
            <span class="author-block">
              <a href="https://zhaoj9014.github.io/">Jian Zhao</a><sup>7†</sup>, 
            </span>
            <span class="author-block">
              <a href="https://sites.google.com/view/fromandto">Hao Zhao</a><sup>1†</sup>
            </span>
          </div>
          <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Institute for AI Industry Research (AIR), Tsinghua University</span> &nbsp;&nbsp;
            <span class="author-block"><sup>2</sup>Imperial College London</span> &nbsp;&nbsp;
            <span class="author-block"><sup>3</sup>Beihang University</span> &nbsp;&nbsp;
            <span class="author-block"><sup>4</sup>Beijing Institute of Technology</span> &nbsp;&nbsp;
            <span class="author-block"><sup>5</sup>University of Chinese Academy of Sciences</span> &nbsp;&nbsp;
            <span class="author-block"><sup>6</sup>The Chinses University of Hong Kong (SZ)</span> &nbsp;&nbsp;
            <span class="author-block"><sup>7</sup>EVOL Lab, Institute of AI (TeleAI), China Telecom</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="../../data/SUNDAE.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://arxiv.org/abs/2405.00676"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
          
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/RunyiYang/SUNDAE"
                   class="external-link button is-normal is-rounded is-dark disabled">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/RunyiYang/SUNDAE-viewer"
                   class="external-link button is-normal is-rounded is-dark disabled">
                  <span class="icon">
                      <i class="fab fa-dribbble"></i>
                  </span>
                  <span>Viewer</span>
                  </a>
              </span>
  

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column is-full-width">
      
          <video class="video" width="100%" id="xyalias6" loop playsinline autoplay muted src="resources/bicycle_zoomoutin.mp4" onplay="resizeAndPlay(this)" style="height: 0px;"></video>
          <video class="video" width="40%" id="xyalias6" loop playsinline autoplay muted src="resources/bicycle_zoomoutin.mp4" onplay="resizeAndPlay(this)" style="height: 0px;"></video> 
          <canvas height=0 class="videoMerge" id="xyalias6Merge"></canvas>
      
          <h2 class="subtitle has-text-centered" style="margin-top: 15px">
            <b>TL;DR</b>: We introduce SA-GS, a training-free approach that can be directly applied to the inference process of any pretrained 3DGS model to resolve its visual artefacts at drastically changed rendering settings.
          </h2>
        </div>
      </div>
    </div>
  </div>
</section> -->

<section class="section">
  <div class="container is-max-desktop">

    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <!-- <h2 class="title is-3" style="margin-top: -20px">Motivation</h2> -->
        <img src="./assets/model_images/teaser.png" class="center" style="width: 100%;">
        <div class="content has-text-justified">
          <p style="margin-top: 0px">
            (a) 3D Gaussian splatting (3DGS) results trained for 7K iterations. (b) 3DGS results trained for 30K iterations, in whichmore Gaussian primitives are allocated so quality gets higher, speed gets slower, and storage gets larger compared to (a). (c) SUNDAE results by pruning 90% primitives upon (a), being much smaller in storage, more accurate and a little bit slower than (a). Note that the storage usage is not 10% of (a) because an additional neural compensation head is used.
          </p>
        </div>
      </div>
    </div>
    <!--/ Animation. -->
  </div>
</section>

<section class="section", style="background-color: #f1f1f1;">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
    
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="margin-top: -30px">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recently, 3D Gaussian Splatting, as a novel 3D representation, has garnered attention for its fast rendering speed and high rendering quality.  However, this comes with high memory consumption, e.g., a well-trained Gaussian field may utilize three million Gaussian primitives and over 700 MB of memory. We credit this high memory footprint to the lack of consideration for the <b>relationship</b> between primitives. In this paper, we propose a memory-efficient Gaussian field named SUNDAE with spectral pruning and neural compensation. On one hand, we construct a graph on the set of Gaussian primitives to model their <b>relationship</b> and design a spectral down-sampling module to prune out primitives while preserving desired signals. On the other hand, to compensate for the quality loss of pruning Gaussians, we exploit a lightweight neural network head to mix splatted features, which effectively compensates for quality losses while capturing the <b>relationship</b> between primitives in its weights. We demonstrate the performance of SUNDAE with extensive results. For example, SUNDAE can achieve 26.80 PSNR at 145 FPS using 104 MB memory while the vanilla Gaussian splatting algorithm achieves 25.60 PSNR at 160 FPS using 523 MB memory, on the Mip-NeRF360 dataset.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <!-- Paper video. -->
    <!--
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    -->
    <!--/ Paper video. -->
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="margin-top: -20px">Motivation & Methods</h2>
        <img src="./assets/model_images/teaser2.png" class="center" style="width: 50%;">
        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            <b>Relationship among Gaussian Primitives.</b> The left panel shows vanilla 3D Gaussian splatting, which requires a large amount of storage as it does not capture the relationship between primitives. The middle panel shows our spectral pruning technique that is based upon the relationship between 3D Gaussians. The right panel shows that the neural compensation head exploits the relationship between 2D feature splatting results to improve rendering.
          </p>
        </div>
        <br><br>
        <img src="./assets/model_images/main.png" class="center">
        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            <b>(a) Pipeline:</b> Our proposed method warms up a 3D Gaussian field firstly, followed by a Graph-based pruning strategy to down-sample the Gaussian primitives, and a convolutional neural network to compensate the losses caused by pruning.
            <br>
            <b>(b) Graph-based Pruning:</b> A graph based on the spatial relationship between the Gaussian primitives, is utilized for pruning post warm-up. Employing a band-limited graph filter, this process facilitates the extraction of fine details from high-frequency components, alongside capturing general features from low-frequency parts, thereby enabling a comprehensive and efficient representation of the entire scene.
          </p>
        </div>
        <!-- <img src="./assets/model_images/Graph.png" class="center">
        <div class="content has-text-justified">
          <h3 class="title is-4">Graph Construction</h3>
          <p>Given a set of Gaussian Primitives \( P \), we want to construct a nearest neighbor graph. The adjacent matrix \( W \) of the graph is defined as:</p>
          <p>\[
          W_{ij}=\left\{
          \begin{array}{rcl}
          &\exp({-\frac{||x_i- x_j||^2}{2*\sigma ^2}}),    \quad & { ||x_i-x_j||^2 < \tau} \\
           & 0,    & otherwise
          \end{array}\right.
          \]</p>
          <p>where \( x_i \) and \( x_j \) are central points in \( P \), \( \tau \) is a hyperparameter, chosen as ten times of the minimum nearest neighborhood distance between primitives experimentally, and \( \sigma \) is the variance of the distance matrix. Equation \( W_{ij} \) demonstrates that when the Euclidean distance of two Gaussian primitives is smaller than a threshold \( \tau \), the two primitives are connected by the graph edge, whose weight corresponds to geometric information between two primitives in Gaussian fields. A weighted degree matrix \( D \) is a diagonal matrix \( D_{i,i} = \sum_j W_{i,j} \), reflecting the density around the \( i \)-th primitive.</p>

          <h3 class="title is-4">Graph Filtering and Sampling</h3>
          <p>We propose a band-limited graph filter, combined with a high-frequency filter and low-frequency filter, to catch the detailed information and general information of the scene. Specifically, the input graph signal \( x \) represents the central of Gaussian primitives.</p>
      
          <p>A simple design of a high-pass filter is a Haar-like one:</p>
          <p>\[
              \mathcal{H}_H = I - A = V (I - \Lambda) V^{-1},
          \]</p>
          <p>where \( A \) is the graph shift and \( V \) and \( \Lambda \) are the corresponding eigenvectors and eigenvalues in diagonal form. Denote that all eigenvalues are \( \lambda_i, i \in \{0, 1, ..., N-1\} \). We order \( \lambda_i \) in descending order, thus we have \( 1 - \lambda_i \leq 1 - \lambda_{i+1} \) and \( \lambda_0 = 1 \). This indicates low-frequency response attenuates and high-frequency response amplifies.</p>
          <p>Similarly, a Haar-like low-pass graph filter is:</p>
          <p>\[
              \mathcal{H}_L = I + \frac{A}{\lambda_0} = V (I + \Lambda / \lambda_0 ) V^{-1}.
          \]</p>
          <p>Then we have the response of the input signal \( x \) corresponding to filters and the response magnitude could be written as:</p>
          <p>\[
              \pi_i = ||f_i||^2.
          \]</p>
        </div> -->
      
        <!-- <img src="./assets/model_images/SI.png" class="center" width="50%">
        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            <b>Super Sampling and Integration applied on Gaussian.</b> Our super sampling method, denoted as <b>(a)</b>, involves dividing each pixel thread into 9 sub-pixels when
            traversing the base-ordered Gaussian within a tile. Each sub-pixel independently undergoes α-blending and weights the Gaussian spherical harmonic coefficient according
            to the sampling results. <b>(b)</b> is our integration method that diagonalizes the Gaussian covariance matrix by pixel rotation. This decomposes the integration result into the
            product of two marginal Gaussian distributions.
          </p>
        </div> -->

      </div>
    </div>
    <!--/ Animation. -->
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">

    <!-- Results. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Results</h2>
        <img src="./assets/model_images/table.png" class="center">
        <br><br>
        <p style="text-align:justify">Our method effectively balances high rendering performance, speed, and efficient memory usage, demonstrating significant advancements. Specifically, at 30% and 50% sampling rates, it manages to deliver top-tier performance metrics while achieving rapid rendering speeds of 88 FPS and maintaining a manageable memory footprint of 393MB. This balance showcases the strength of our spectral pruning and neural compensation techniques, which adeptly handle the relationships among Gaussian primitives, ensuring minimal quality loss even when reducing the abundance of primitives. The efficiency of our approach is further highlighted by the SUNDAE variant, which at very low sampling rates like 10% and even 1%, still offers remarkable rendering efficiency and reduced memory demands, maintaining competitive image quality. Overall, our method stands out for its robustness and capability to optimize the trade-offs between quality, speed, and memory usage in complex rendering environments.
        </p>
        <!-- <div class="row_two_columns">
          <div class="content has-text-lefted">
            <video class="video" width="100%" id="xyalias1" loop playsinline autoplay muted src="resources/360_zoomout.mp4" onplay="resizeAndPlay3(this)" ></video>
            <canvas height=0 class="videoMerge" id="xyalias1Merge3"></canvas>
          </div>
          <div class="content has-text-righted">
            <video class="video" width="100%" id="xyalias11" loop playsinline autoplay muted src="resources/360_zoomin.mp4" onplay="resizeAndPlay3(this)" ></video>
            <canvas height=0 class="videoMerge" id="xyalias11Merge3"></canvas>
          </div>
        </div> -->
        <br><br>
        <div class="container">
          <ul class="nav nav-tabs nav-fill nav-justified" id="object-scale-recon">
              <li class="nav-item">
                <a class="nav-link active" onclick="objectSceneEvent(0)">Bicycle</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="objectSceneEvent(1)">Counter</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="objectSceneEvent(2)">Garden</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="objectSceneEvent(3)">Kitchen</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="objectSceneEvent(4)">Room</a>
              </li>
          </ul>
          <ul class="nav nav-tabs nav-fill nav-justified" id="object-scale-recon">
            <li class="nav-item">
              <a class="nav-link" onclick="objectSceneEvent(5)">Stump</a>
            </li>
            <li class="nav-item">
              <a class="nav-link active" onclick="objectSceneEvent(6)">DrJohnson</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" onclick="objectSceneEvent(7)">PlayRoom</a>
            </li>
            <li class="nav-item">
              <a class="nav-link" onclick="objectSceneEvent(8)">Train</a>
            </li>
          </ul>
          <div class="b-dics" style="width: 700px; font-weight: 600;margin:auto">
              <img src="./assets/360_images/Bicycle/3DGS.png" alt="3DGS">
              <img src="./assets/360_images/Bicycle/Ours-1.png" alt="SUNDAE-1%">
              <img src="./assets/360_images/Bicycle/Ours-10.png" alt="SUNDAE-10%">
              <img src="./assets/360_images/Bicycle/InstantNGP.png" alt="InstantNGP">
              <img src="./assets/360_images/Bicycle/GT.png" alt="GT">
          </div>
        </div>

        <br><br>
        <!-- <h3 class="title is-4 has-text-centered">Comparison on Blender Dataset</h3>
        <div class="content has-text-justified">
          <p>
            We show both zoom-out and zoom-in cases in different scenarios. We highlight the contrasting areas. Our method obtains robust anti-aliasing 
            performance improvements over 3DGS, while significantly outperforming Mip-Splatting in the zoom-out case.
          </p>
        </div>

        <div class="content has-text-centered">
          <video class="video" width="100%" id="xyalias12" loop playsinline autoplay muted src="resources/blender.mp4"></video>
          <canvas height=0 class="videoMerge" id="xyalias12Merge"></canvas>
        </div>

        <div class="container">
          <ul class="nav nav-tabs nav-fill nav-justified" id="ablation-3d-filter">
              <li class="nav-item">
                <a class="nav-link active" onclick="ablation3DEvent(0)">chair(1/8x)</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="ablation3DEvent(1)">ficus(1/8x)</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="ablation3DEvent(2)">ship(1/8x)</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="ablation3DEvent(3)">drum(8x)</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="ablation3DEvent(4)">hotdog(8x)</a>
              </li>
              <li class="nav-item">
                <a class="nav-link" onclick="ablation3DEvent(5)">mic(8x)</a>
              </li>
          </ul>
          <div class="b-dics" style="width: 1000px; font-weight: 600;">
            <img src="resources/blender_images/chair_raw.png" alt="3DGS">
            <img src="resources/blender_images/chair_mip.png" alt="Mip-Splatting">
            <img src="resources/blender_images/chair_int.png" alt="SA-GS Integration (Ours)">
            <img src="resources/blender_images/chair_sup.png" alt="SA-GS Super Sampling (Ours)">
            <img src="resources/blender_images/chair_gt.png" alt="GT">
          </div>
        </div>

        <br><br>
        <h3 class="title is-4 has-text-centered">Effectiveness of 2D Scale-adaptive Filter</h3>
        <div class="content has-text-justified">
          <p>
            The 2D scale-adaptive filter maintains the consistency of the Gaussian distribution when zooming out, 
            which in turn fully unleashes the power of the integral and supersampling antialiasing methods. Additionally, 
            the filter removes erosion artifacts from the scene when zooming in, resulting in a more structurally uniform scene.
          </p>
        </div>
        <div class="row_two_columns">
          <div class="content has-text-lefted">
            <video class="video" id="filter_ablation_zoomout" loop playsinline autoplay muted src="resources/filter_abaltion_zoomout.mp4" onplay="resizeAndPlay3(this)" ></video>
            <canvas height=0 class="videoMerge" id="filter_ablation_zoomoutMerge3"></canvas>
          </div>
          <div class="content has-text-righted" type="width:100px;">
            <video class="video" id="xyalias23" loop playsinline autoplay muted src="resources/filter_ablation_zoomin.mp4" onplay="resizeAndPlay(this)" ></video>
            <canvas height=0 class="videoMerge" id="xyalias23Merge"></canvas>
          </div>
        </div>
      </div>
    </div> -->

  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{yang2024spectrally,
      title={Spectrally Pruned Gaussian Fields with Neural Compensation}, 
      author={Runyi Yang and Zhenxin Zhu and Zhou Jiang and Baijun Ye and Xiaoxue Chen and Yifei Zhang and Yuantao Chen and Jian Zhao and Hao Zhao},
      year={2024},
      eprint={2405.00676},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}</code></pre>
  </div>
</section>

<!-- <section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    ZY, AC and AG are supported by the ERC Starting Grant LEGO-3D (850533) and DFG EXC number 2064/1 - project number 390727645.
    TS is supported by a Czech Science Foundation (GACR) EXPRO grant (UNI-3D, grant no. 23-07973X).
    We also thank Christian Reiser for insightful discussions during the preparation of the draft.
  </div>
</section> -->

<!-- <section class="section" id="References">
  <div class="container is-max-desktop content">

        <h3 class="title is-4">References</h3>
        <div class="content has-text-justified">
          <ul>
            <li>
              <a href="https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/" target="_blank">3D Gaussian Splatting for Real-Time Radiance Field Rendering</a>
            </li>
            <li>
              <a href="https://www.cs.umd.edu/~zwicker/publications/EWASplatting-TVCG02.pdf" target="_blank">EWA Splatting</a>
            </li>
          </ul>
        </div>
      </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
            This webpage template is from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. 
            We sincerely thank <a href="https://keunhong.com/">Keunhong Park</a> for developing and open-sourcing this template. 
            <!-- The video comparison with sliding bar is from <a href="https://dorverbin.github.io/refnerf/">Ref-NeRF</a>.  -->
            <!-- The image comparison with sliding bar is from <a href="https://research.nvidia.com/labs/dir/neuralangelo/">Neuralangelo</a>.  -->
          </p>
        </div>
      </div>
          <p></p>
        </div>
      </div>
</footer>

</body>
</html>
